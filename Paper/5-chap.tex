\chapter{\chapFive}
\label{cha:chapter5} % Label for hyperlink

% Start font-size
\begingroup
\fontsize{12pt}{14pt}\selectfont

\section{Fazit}
Wie im vorherigen Kapitel beschrieben, bestehen deutliche Effizienzunterschiede zwischen den beiden Ansätzen.
Es ist ebenfalls erkennbar, dass eine Platzierung mit grösseren Abständen zwischen den Markern sich positiv auf die Genauigkeit und Zuverlässigkeit einer gestenbasierten Steuerung auswirkt.
Es darf jedoch nicht vergessen werden, dass Methode~1 teilweise so schlecht abgeschnitten hat, weil die Handoberfläche nicht eben ist.
Hätten bei Methode~1 die Marker ebenfalls die Form einer Raute gebildet, wäre kein Marker direkt auf dem Thenarmuskel gelegen und es wäre ein grösserer Erkennungsbereich-Winkel verfügbar gewesen.
Insofern werden die Ergebnisse dieser Arbeit etwas verfälscht.
Aber auch wenn die Marker anders auf der Handfläche ausgelegt worden wären, so wäre die Sensibilität immer noch höher als bei Methode~2 und somit für die meisten unangenehmer zu benutzen.

Das Ziel der Arbeit wurde erreicht.
Es konnte eine Steuerungsalternative entwickelt werden, die die Erkennung von Handpositionen erfolgreich implementiert.
Auch die Konzepte der Gestenerkennung sowie deren Einsatzmöglichkeiten zur Steuerung virtueller Systeme konnten veranschaulicht werden.

\section{Rückblick}

Rückblickend zeigte sich, dass die gewählte Lösung mit ArUco-Markern zwar eine robuste und vergleichsweise einfache Möglichkeit zur Gestenerkennung ist, jedoch auch einige Einschränkungen aufweist.
Die Marker müssen klar sichtbar und korrekt beleuchtet sein, was die praktische Anwendbarkeit reduziert.
Zudem wirkt die Interaktion durch die sichtbaren Markierungen weniger natürlich.

Ein alternativer Ansatz wäre die Verwendung einer echten Handerkennung gewesen, beispielsweise mit der Python-Bibliothek MediaPipe in Kombination mit OpenCV.
Diese Methode hätte eine markerlose Steuerung ermöglicht und damit eine natürlichere Mensch-Maschine-Interaktion geschaffen.
Zum Zeitpunkt der Planung wurde dieser Weg jedoch verworfen, da der Implementierungsaufwand und die technische Komplexität zu hoch eingeschätzt wurden.
Rückblickend wäre es jedoch ein lohnendes Experiment gewesen, um das Potenzial einer rein visuellen Gestensteuerung zu untersuchen.

\section{Zukunft und Weiterentwicklung}

In zukünftigen Arbeiten soll die Steuerung der Crazyflie auf eine markerlose Handerkennung umgestellt werden.
Die Kombination aus MediaPipe und OpenCV bietet dafür eine geeignete Grundlage, um Gesten in Echtzeit zu erkennen und deren Position sowie Ausrichtung präzise zu bestimmen.
Durch diese Erweiterung könnte die Steuerung deutlich natürlicher und intuitiver werden, da keine sichtbaren Marker mehr benötigt würden.

Das Ziel ist es, diesen Ansatz in einem nächsten Schritt praktisch umzusetzen und zu evaluieren, wie zuverlässig und reaktionsschnell die Drohne auf reine Handbewegungen reagiert.
Dabei steht insbesondere die Stabilität der Erkennung im Vordergrund.

% End font-size
\endgroup