ar\chapter{\chapThree}
\label{cha:chapter3} % Label for hyperlink

% Start font-size
\begingroup
\fontsize{12pt}{14pt}\selectfont

In diesem Kapitel wird beschrieben, wie die im Kapitel 2 vorgestellten theoretischen Grundlagen praktisch umgesetzt werden.
Ziel ist es, eine Gestensteuerung der Crazyflie 2.0 mithilfe von ArUco-Markern zu realisieren.
Um dieses Ziel zu erreichen, wurde eine Methode entwickelt, die sowohl die Erkennung und Analyse von Handbewegungen als auch die Steuerung der Drohne umfasst.

\section{Vorgehensweise}

Diese Arbeit umfasst mehrere Prozessschritte, die von der Erfassung visueller Daten über deren mathematische Verarbeitung bis hin zur Umsetzung in Steuerbefehle für die Drohne reichen.
Dazu werden folgende Schritte durchgeführt:

\begin{enumerate}
    \item \textbf{Erfassen der Handbewegung:}
    \begin{itemize}
        \item Kameraerfassung der ArUco-Marker auf der Hand.
        \item Verarbeitung der Bilder mit OpenCV.
        \item Extraktion der Markerpositionen und Eckpunkte.
    \end{itemize}
    \item \textbf{Datenverarbeitung und Interpretation:}
    \begin{itemize}
        \item Flächenberechnung jedes Markers mittels Gaußscher Trapezformel.
        \item Bestimmung der Ausrichtung der Handfläche.
    \end{itemize}
    \item \textbf{Steuerung der Crazyflie:}
    \begin{itemize}
        \item Übersetzung der Handausrichtung in Steuerargumente.
        \item Verwendung dieser Argumente in den CFLib-Funktionen.
        \item Übertragung der Befehle über das Crazyradio PA via CRTP.
    \end{itemize}
\end{enumerate}

\section{Erfassen der Handbewegung}

Zu Beginn muss die OpenCV-Bibliothek in das Python-Skript importiert werden, da sie die grundlegenden Funktionen für die Bildverarbeitung bereitstellt.
Für die Erfassung der Handbewegung ist der Zugriff auf die Kamera erforderlich.
Dies erfolgt über die Klasse \bodyCode{VideoCapture()}, die eine Verbindung zur Kamera herstellt und kontinuierlichen Zugriff auf deren Bilddaten ermöglicht.
Ob die Kamera erfolgreich geöffnet wurde oder beispielsweise durch ein anderes Programm blockiert ist, kann mit der integrierten Funktion \bodyCode{isOpened()} überprüft werden.

Um sicherzustellen, dass tatsächlich Bildinformationen empfangen werden, muss in einer Schleife die \bodyCode{read()}-Funktion aufgerufen werden.
Diese gibt zwei Werte zurück:

\begin{itemize}
    \item Der erste Wert gibt an, ob ein Bild erfolgreich empfangen wurde\footnotemark{}.
    \footnotetext{Im \hTeLi{sni:cam}{Codeausschnitt} als \bodyCode{success} ersichtlich.}
    \item Der zweite Wert enthält das aktuelle Kamerabild in Form eines NumPy-Arrays\footnotemark{}.
    \footnotetext{Im \hTeLi{sni:cam}{Codeausschnitt} als \bodyCode{frame} ersichtlich.}
\end{itemize}

Wenn kein Bild empfangen werden konnte, wird das Programm beendet.
Anschliessend wird das Bild in Graustufen konvertiert, um die spätere Erkennung der ArUco-Marker zu erleichtern.
Die Spiegelung entlang der vertikalen Achse sorgt dafür, dass das angezeigte Bild der realen Ausrichtung der Hand entspricht.

\codefile[cam.py]{Codeausschnitt: Initialisierung der Kamera}{sni:cam}


\section{Datenverarbeitung und Interpretation}

\section{Steuerung der Crazyflie}
\label{sec:cf_co}

% End font-size
\endgroup