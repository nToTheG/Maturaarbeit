\chapter{\chapOne}
\label{cha:chapter1} % Label for hyperlink

% Start font-size
\begingroup
\fontsize{12pt}{14pt}\selectfont

\section{Einführung ins Thema}
Gestenerkennung und Gestensteuerung haben sich in den letzten Jahren von Nischenanwendungen im Gaming-Bereich wie beispielsweise der Kinect-Plattform~\cite{Wiki:Kinect} zu vielseitigen Steuerungsmöglichkeiten für virtuelle und reale Umgebungen entwickelt~\cite{RG:GestureRecognition}.
Ihre Wurzeln liegen teilweise in der Analyse der Gebärdensprache, reichen jedoch letztlich bis zu den Anfängen menschlicher Kommunikation zurück.\cite{Wiki:Gestenerkennung}\cite{RG:Gesten}
Gesten stellen einen festen und wesentlichen Bestandteil der nonverbalen Verständigung dar und bilden somit eine natürliche Grundlage für intuitive Interaktionsformen zwischen Mensch und Maschine.\cite[10]{Hobmair:Psy}

Parallel dazu gewinnt die autonome Steuerung technischer Systeme zunehmend an Bedeutung.
Fahrzeuge, die mit modernen Fahrassistenzsystemen ausgestattet sind, können heute vom Spurhalten bis zum automatischen Parkieren fast alles selbstständig ausführen.
Doch nicht nur im Strassenverkehr, auch in der Luft- und Schifffahrt werden Prozesse automatisiert, um Effizienz und Sicherheit zu erhöhen und menschliche Fehler zu minimieren.
Trotz dieser Entwicklungen bleibt der Mensch ein zentraler Bestandteil des Kontrollsystems: Er kann jederzeit in den automatisierten Ablauf eingreifen und die Steuerung übernehmen.\cite{Wiki:aupi}

Noch rasanter schreitet die Entwicklung im Bereich der virtuellen und erweiterten Realität (VR und AR) voran~\cite{SD:VR}.
Hier ermöglichen innovative Interaktionskonzepte eine immer natürlichere, präzisere und intuitivere Steuerung digitaler Umgebungen.
Ein beeindruckendes Bespiel ist dabei die \textit{Apple Vision Pro}, eine VR-Brille, die im Jahr 2023 auf den Märkten erschienen ist.
Das Gerät verfolgt die Bewegung der Augen und verwendet diese als Gestensteuerung und erlaubt es durch Zusammenführen von Daumen und Zeigefinger Objekte auf dem virtuellen Bildschirm auszuwählen.\cite{apl:vision}

Auch in der Robotik eröffnen Gestensteuerungssysteme neue Perspektiven: Sie erlauben eine direkte, beinahe natürliche Kommunikation mit semi-autonomen oder autonomen Geräten, etwa bei der Navigation von Drohnen oder mobilen Robotern.
So können beispielsweise Bergungsarbeiten oder Minenräumungen künftig aus sicherer Entfernung durchgeführt werden, ohne dabei Menschen unnötigen Gefahren auszusetzen.

\section{Zielsetzung der Arbeit}
Das Ziel dieser Arbeit ist es, die Konzepte der Gestenerkennung sowie deren Einsatzmöglichkeiten zur Steuerung virtueller Systeme zu veranschaulichen.
Als Grundlage dient dabei ein ähnliches Projekt, welches ein neurales Netzwerk zur Erkennung von Handpositionen implementiert, um eine Steuerungsalternative zu traditionellen Kontrollern zu bieten.
Die Position der Hand wird von einer Kamera erfasst und von einem Computer ausgewertet.
Dieser sendet Steuerbefehle anhand der berechneten Daten an einer Renndrohne.\cite{arxiv:OmniRace}

Um den Aufwand in einem realistischen Rahmen zu halten, wird in dieser Arbeit nicht auf eine direkte Erkennung der Fingerpositionen gesetzt.
Stattdessen kommen vier ArUco-Marker zum Einsatz, die auf der Steuerhand befestigt werden.
Dies soll eine präzise Erkennung der Handausrichtung ermöglichen, indem Flächen, Positionen und Distanzen der Marker berechnet und verglichen werden.
Anschliessend wird mit den in \hTeLi{sec:cf}{Kapiteln~\ref{sec:cf}} und \hTeLi{sec:crpa}{\ref{sec:crpa}} beschriebenen Hardware-Komponenten eine Drohne gesteuert.

In diesem Projekt werden zwei Ansätze getestet, die sich in der Platzierung der Marker unterscheiden.
Die Anordnung der Marker soll die Bedeutsamkeit veranschaulichen, die Finger beim Gebrauch von Gesten haben.
Der erste Ansatz sieht die Marker in einem Rechteck angeordnet vor, wobei ausschliesslich die Handfläche als Bereich für die Marker dient.
Der zweite Versuch setzt hingegen drei von vier Markern auf den Fingerspitzen vorraus.
Der vierte Marker wird auf dem Handgelenk platziert und markiert für die Kamera den Referenzpunkt der Hand.

\subsection{Fragestellung}
Wie kann ein System zur gestenbasierten Steuerung einer Nano-Drohne entwickelt werden, das mithilfe von ArUco-Markern Handgesten zuverlässig erkennt, diese in präzise Steuerbefehle umwandelt und die Drohne per  Funkverbindung sicher und reaktionsschnell steuert?

\subsection{Abgrenzung (ausgeschlossene Faktoren)}
Im Rahmen dieses Projekts werden externe Einflussfaktoren bewusst ausgeklammert bzw. nicht im Detail untersucht.
Dazu gehören insbesondere:
\begin{itemize}
  \item \textbf{Licht- und Belichtungsverhältnisse:} Es wird von konstanten, guten Lichtverhältnissen ausgegangen (z.B. gleichmässige Raumbeleuchtung ohne starke Schatten oder Überbelichtung).
  \item \textbf{Wind- und Luftströmungen:} Das System wird ausschliesslich in einer windstillen Indoor-Umgebung getestet.
  \item \textbf{Funkstörungen:} Potenzielle Interferenzen durch andere Funkgeräte oder Netzwerke werden nicht berücksichtigt.
  \item \textbf{Komplexe Handgesten:} Es wird davon ausgegangen, dass die ArUco-Tags jederzeit für die Kamera sichtbar bleiben.
\end{itemize}

\subsection{Hypothese}
Die Nutzung von ArUco-Markern zur Gestenerkennung ermöglicht eine robuste Gestensteuerung der Drohne, wobei Positions- und Bewegungsdaten der Marker ausreichend präzise sind, um alle grundlegenden Steuerbefehle (z.B. Steigen, Sinken, Drehen) sicher und ohne Fehlinterpretationen auszuführen.

% End font-size
\endgroup